{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:35:09.643836Z",
     "start_time": "2023-03-02T07:34:57.434854Z"
    },
    "id": "6YWw5a_h-kg-"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from google.colab import files, drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIZp7OIJqGN3"
   },
   "source": [
    "### 1 - Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "id": "N8fJAO_VvAIW"
   },
   "outputs": [],
   "source": [
    "# Useful functions for ploting figures of paper and implementation RMSE metric.\n",
    "\n",
    "def history_plot(model1, model2, title1, title2):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "    fig.set_figheight(6)\n",
    "    fig.set_figwidth(12)\n",
    "\n",
    "    ax1.plot(model1.epoch, model1.history['loss'],\n",
    "             color='forestgreen', label='Train')\n",
    "    ax1.plot(model1.epoch, model1.history['val_loss'],\n",
    "             color='lightcoral', label='Validation')\n",
    "    ax1.set_xlabel('Epochs', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title(label=title1, size=14)\n",
    "    ax1.grid(True, ls='--')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(model2.epoch, model2.history['loss'],\n",
    "             color='forestgreen', label='Train')\n",
    "    ax2.plot(model2.epoch, model2.history['val_loss'],\n",
    "             color='lightcoral', label='Validation')\n",
    "    ax2.set_xlabel('Epochs', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.set_title(label=title2, size=14)\n",
    "    ax2.grid(True, ls='--')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.savefig('history_curve.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def correlation_plot(y_true, y_pred):\n",
    "\n",
    "    ax = sns.jointplot(y_true, y_pred, facecolor='lightsteelblue',\n",
    "                       edgecolor='c', marginal_kws={'color': 'darkcyan'})\n",
    "    ax.set_axis_labels('Experimental', 'Predicted', fontsize=13)\n",
    "    ax.fig.suptitle('Test set $R_{P}$ = 0.79', fontsize=14)\n",
    "    ax.fig.tight_layout()\n",
    "    ax.fig.subplots_adjust(top=0.9)\n",
    "\n",
    "    plt.savefig('correlation_plot.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def bar_chart(input, colormap, xlabel, filename):\n",
    "\n",
    "    my_cmap = plt.cm.get_cmap(colormap)\n",
    "    plt.figure(figsize=(6, 10))\n",
    "    plt.barh(range(len(input) + 1, 1, -1), np.array(input)\n",
    "             [:, 1], color=my_cmap(range(1, (len(input) + 1) * 4, 4)))\n",
    "    plt.yticks(range(len(input) + 1, 1, -1),\n",
    "               np.array(input, dtype=int)[:, 0], fontsize=10)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel('Target Cluster ID', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    dev = np.square(y_true.ravel() - y_pred.ravel())\n",
    "    return np.sqrt(np.sum(dev) / y_true.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCfwAJCeG_t1"
   },
   "source": [
    "### 2 - Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zZyeG6Bbyet"
   },
   "source": [
    "#### PDBbind 2016v. dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T07:38:18.091556Z",
     "start_time": "2023-03-02T07:38:17.257900Z"
    },
    "id": "bRzZ3uQDbxjo"
   },
   "outputs": [],
   "source": [
    "# opening refined set data.\n",
    "\n",
    "with open('refined_set_data.pickle', 'rb') as handle:\n",
    "    refined_set_data = pickle.load(handle)\n",
    "\n",
    "# opening general minus refined set data.\n",
    "\n",
    "with open('general_minus_refined_set_data.pickle', 'rb') as handle:\n",
    "    general_minus_refined_set_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5x_PV9pcOH9"
   },
   "outputs": [],
   "source": [
    "# loading pKd values for genral, refined and core set data.\n",
    "\n",
    "general_set = pd.read_csv('general_set_binding_data.csv', index_col=0)\n",
    "refined_set = pd.read_csv('refined_minus_core_set_binding_data.csv')\n",
    "core_set = pd.read_csv('core_set_binding_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrld7ZVil6sb"
   },
   "outputs": [],
   "source": [
    "# some pdbid in general set don't have structures. Following codes find out these missing structures.\n",
    "\n",
    "g_s_m = set(list(refined_set_data.keys()) +\n",
    "            list(general_minus_refined_set_data.keys()))\n",
    "g_s = set(general_set['pdbid'].to_list())\n",
    "missing = list(g_s.difference(g_s_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q13AfGJ2meS5"
   },
   "outputs": [],
   "source": [
    "# droping missing data from genral set\n",
    "\n",
    "general_set = general_set.set_index('pdbid')\n",
    "general_set.drop(missing, axis=0, inplace=True)\n",
    "general_set.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpH0tXXTctoS"
   },
   "outputs": [],
   "source": [
    "# making training and validation set\n",
    "\n",
    "core_set_pdbid = core_set['pdbid'].to_list()\n",
    "\n",
    "general_set = general_set.set_index('pdbid')\n",
    "\n",
    "general_set.drop(core_set_pdbid, axis=0, inplace=True)\n",
    "\n",
    "general_set.reset_index(inplace=True)\n",
    "\n",
    "general_set['ba_cat'] = np.ceil(general_set['binding_affinity']/1.5)\n",
    "\n",
    "general_set['ba_cat'].where(general_set['ba_cat'] < 8, 8, inplace=True)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.077, random_state=42)\n",
    "\n",
    "for train_index, val_index in split.split(general_set, general_set['ba_cat']):\n",
    "    strat_train_set = general_set.loc[train_index]\n",
    "    strat_val_set = general_set.loc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdjTLw6oeykb"
   },
   "outputs": [],
   "source": [
    "# pdbid of train, validation and test(core) set\n",
    "\n",
    "strat_train_set_pdbid = strat_train_set['pdbid'].to_list()\n",
    "strat_val_set_pdbid = strat_val_set['pdbid'].to_list()\n",
    "core_set_pdbid = core_set['pdbid'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8BcdSVQfWoX"
   },
   "outputs": [],
   "source": [
    "# making input and target for train, validation and test(core) set\n",
    "\n",
    "strat_train_set_x = []\n",
    "strat_val_set_x = []\n",
    "\n",
    "for key in strat_train_set_pdbid:\n",
    "    try:\n",
    "        strat_train_set_x.append(general_minus_refined_set_data[key])\n",
    "    except Exception:\n",
    "        strat_train_set_x.append(refined_set_data[key])\n",
    "\n",
    "for key in strat_val_set_pdbid:\n",
    "    try:\n",
    "        strat_val_set_x.append(general_minus_refined_set_data[key])\n",
    "    except Exception:\n",
    "        strat_val_set_x.append(refined_set_data[key])\n",
    "\n",
    "strat_train_set_x = np.array(strat_train_set_x).reshape(\n",
    "    len(strat_train_set_pdbid), 60, 100, 1)\n",
    "strat_val_set_x = np.array(strat_val_set_x).reshape(\n",
    "    len(strat_val_set_pdbid), 60, 100, 1)\n",
    "test_set_x = np.array([refined_set_data[key]\n",
    "                      for key in core_set_pdbid]).reshape(285, 60, 100, 1)\n",
    "\n",
    "strat_train_set_y = strat_train_set['binding_affinity'].to_numpy()\n",
    "strat_val_set_y = strat_val_set['binding_affinity'].to_numpy()\n",
    "test_set_y = core_set['binding_affinity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5608,
     "status": "ok",
     "timestamp": 1601220072733,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -210
    },
    "id": "w7n8mAwDoeb3",
    "outputId": "59938a0e-2420-4d7c-91c0-827c19c52c66"
   },
   "outputs": [],
   "source": [
    "# shape of train, validation and test(core) set\n",
    "\n",
    "print('X Train: ', strat_train_set_x.shape)\n",
    "print('X Val: ', strat_val_set_x.shape)\n",
    "print('X Test: ', test_set_x.shape)\n",
    "print('Y Train: ', strat_train_set_y.shape)\n",
    "print('Y Val: ', strat_val_set_y.shape)\n",
    "print('Y Test: ', test_set_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvqUNLX2cJRQ"
   },
   "source": [
    "### 3 - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK7ZwX_Nh7f8"
   },
   "source": [
    "#### 3-1 Residual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4AgMaWm6Vic"
   },
   "outputs": [],
   "source": [
    "# Implemention Residual model using Tensorflow functional API.\n",
    "\n",
    "def resiual_module(x, filters):\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(\n",
    "        filters, 3, 2, padding='SAME', use_bias=False)(x)\n",
    "    batch1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv2 = tf.keras.layers.Conv2D(\n",
    "        filters, 3, 1, padding='SAME', use_bias=False)(batch1)\n",
    "    conv3 = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=2)(x)\n",
    "    batch2 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    activation = tf.keras.activations.get('relu')\n",
    "\n",
    "    return activation(tf.add(conv2, batch2))\n",
    "\n",
    "\n",
    "def create_residual_functional_model(input_size, dropout=0.1):\n",
    "\n",
    "    input = tf.keras.layers.Input(input_size)\n",
    "    conv1 = tf.keras.layers.Conv2D(32, 3, 1, activation='relu')(input)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPool2D(\n",
    "        pool_size=2, strides=2, padding='SAME')(conv1)\n",
    "    for filters in [64, 64, 128, 128, 256]:\n",
    "        res = residual_module(pool1, filters)\n",
    "        pool1 = res\n",
    "    glob1 = tf.keras.layers.GlobalAvgPool2D()(res)\n",
    "    dense1 = tf.keras.layers.Dense(100, activation='relu')(glob1)\n",
    "    batch1 = tf.keras.layers.BatchNormalization()(dense1)\n",
    "    drop1 = tf.keras.layers.Dropout(dropout)(batch1)\n",
    "    dense2 = tf.keras.layers.Dense(50, activation='relu')(drop1)\n",
    "    batch2 = tf.keras.layers.BatchNormalization()(dense2)\n",
    "    drop2 = tf.keras.layers.Dropout(dropout)(batch2)\n",
    "    output = tf.keras.layers.Dense(1)(drop2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input], outputs=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z05N53MFJ12M"
   },
   "outputs": [],
   "source": [
    "# Implemention Residual model using Tensorflow custom layer and sequential API.\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n",
    "                        padding='SAME', use_bias=False)\n",
    "\n",
    "\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.strides = strides\n",
    "        self.activation = activation\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            DefaultConv2D(filters, strides=strides),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            DefaultConv2D(filters),\n",
    "            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                keras.layers.BatchNormalization()]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'filters': self.filters, 'strides': self.strides,\n",
    "                'activation': self.activation}\n",
    "\n",
    "\n",
    "def create_residual_custom_model(input_size, dropout=0.1):\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    # model.add(keras.layers.BatchNormalization())\n",
    "    model.add(DefaultConv2D(32, input_shape=input_size))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2, strides=2, padding='SAME'))\n",
    "    for filters in [64, 64, 128, 128, 256]:\n",
    "        model.add(ResidualUnit(filters, strides=2))\n",
    "    model.add(keras.layers.GlobalAvgPool2D())\n",
    "    model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q65IBpXoiDpl"
   },
   "source": [
    "#### 3-2 Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CB6GE-yqAFHd"
   },
   "outputs": [],
   "source": [
    "# Implemenation of Sequential model using Tensorflow sequential API.\n",
    "\n",
    "def create_sequential_model(input_size, dropout=0.1):\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=4, strides=1,\n",
    "                               padding='valid', input_shape=input_size, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, 4, 1, padding='valid', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, 4, 1, padding='valid', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(\n",
    "            400, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "\n",
    "        tf.keras.layers.Dense(\n",
    "            200, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "\n",
    "        tf.keras.layers.Dense(\n",
    "            100, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "\n",
    "        tf.keras.layers.Dense(\n",
    "            20, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Y7GbOWJU71H"
   },
   "source": [
    "#### 3-3 Inception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VRttwfyVSSz"
   },
   "outputs": [],
   "source": [
    "# Implemenation of Inception model using Tensorflow functional API.\n",
    "\n",
    "def inception_module(x,\n",
    "                     filters_1,\n",
    "                     filters_3_reduce,\n",
    "                     filters_3,\n",
    "                     filters_5_reduce,\n",
    "                     filters_5,\n",
    "                     filters_pool):\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(\n",
    "        filters_1, 1, padding='same', activation='relu')(x)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(\n",
    "        filters_3_reduce, 1, padding='same', activation='relu')(x)\n",
    "    conv3 = tf.keras.layers.Conv2D(\n",
    "        filters_3, 3, padding='same', activation='relu')(conv3)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv2D(\n",
    "        filters_5_reduce, 1, padding='same', activation='relu')(x)\n",
    "    conv5 = tf.keras.layers.Conv2D(\n",
    "        filters_5, 5, padding='same', activation='relu')(conv5)\n",
    "\n",
    "    pool = tf.keras.layers.MaxPool2D(3, 1, padding='same')(x)\n",
    "    conv6 = tf.keras.layers.Conv2D(\n",
    "        filters_pool, 1, padding='same', activation='relu')(pool)\n",
    "\n",
    "    output = tf.keras.layers.concatenate([conv1, conv3, conv5, conv6], axis=3)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_inception_model(input_size, dropout=0.1):\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=input_size)\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(\n",
    "        32, 4, 1, padding='same', activation='relu')(input)\n",
    "    pool1 = tf.keras.layers.MaxPool2D(2, 2, padding='same')(conv1)\n",
    "\n",
    "    inception1 = inception_module(pool1, 64, 96, 128, 16, 32, 32)\n",
    "    inception2 = inception_module(inception1, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "    glob1 = tf.keras.layers.GlobalAveragePooling2D()(inception2)\n",
    "\n",
    "    dense1 = tf.keras.layers.Dense(\n",
    "        400, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu')(glob1)\n",
    "    batch1 = tf.keras.layers.BatchNormalization()(dense1)\n",
    "    drop1 = tf.keras.layers.Dropout(dropout)(batch1)\n",
    "\n",
    "    dense2 = tf.keras.layers.Dense(\n",
    "        200, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu')(drop1)\n",
    "    batch2 = tf.keras.layers.BatchNormalization()(dense2)\n",
    "    drop2 = tf.keras.layers.Dropout(dropout)(batch2)\n",
    "\n",
    "    dense3 = tf.keras.layers.Dense(\n",
    "        100, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu')(drop2)\n",
    "    batch3 = tf.keras.layers.BatchNormalization()(dense3)\n",
    "    drop3 = tf.keras.layers.Dropout(dropout)(batch3)\n",
    "\n",
    "    dense4 = tf.keras.layers.Dense(\n",
    "        20, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu')(drop3)\n",
    "    batch4 = tf.keras.layers.BatchNormalization()(dense4)\n",
    "    drop4 = tf.keras.layers.Dropout(dropout)(batch4)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1)(drop4)\n",
    "\n",
    "    model = tf.keras.models.Model(input, output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c98Xqg9CpjiM"
   },
   "source": [
    "### 4 - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JGQMsObipNq"
   },
   "source": [
    "#### 4-1 Residual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSHQzxd--JwP"
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "\n",
    "residual_model = create_residual_custom_model((60, 100, 1))\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=40, monitor='val_mse', restore_best_weights=True)\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "residual_model.compile(optimizer=adam, loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 294597,
     "status": "ok",
     "timestamp": 1599636649073,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -270
    },
    "id": "vVkAR85Vpu_v",
    "outputId": "6c3d540b-226b-44a6-f91b-4921d389a7f6"
   },
   "outputs": [],
   "source": [
    "# Training Residual model\n",
    "\n",
    "residual_history = residual_model.fit(strat_train_set_x, strat_train_set_y, batch_size=128, epochs=500,\n",
    "                                      validation_data=(strat_val_set_x, strat_val_set_y), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_a2meYXBSRd"
   },
   "outputs": [],
   "source": [
    "residual_model.save('residual_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AANRmYP4XqH-"
   },
   "outputs": [],
   "source": [
    "y_pred_test = residual_model.predict(test_set_x)\n",
    "y_pred_val = residual_model.predict(strat_val_set_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1599567358693,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -270
    },
    "id": "E8Gu6gXvbcet",
    "outputId": "4f1a0c77-fe75-49bb-846a-831dc5709a81"
   },
   "outputs": [],
   "source": [
    "# calculating metrics for residual model\n",
    "\n",
    "loss_test = residual_model.evaluate(test_set_x, test_set_y, verbose=0)\n",
    "loss_val = residual_model.evaluate(strat_val_set_x, strat_val_set_y, verbose=0)\n",
    "\n",
    "pcc_test = pearsonr(test_set_y, y_pred_test.ravel())[0]\n",
    "rmse_test = rmse(test_set_y, y_pred_test.ravel())\n",
    "\n",
    "pcc_val = pearsonr(strat_val_set_y, y_pred_val.ravel())[0]\n",
    "rmse_val = rmse(strat_val_set_y, y_pred_val.ravel())\n",
    "\n",
    "print('-------------------')\n",
    "print('Residual Model')\n",
    "print(f'Test Loss: {loss_test[1]:.3f} Val Loss: {loss_val[1]:.3f}')\n",
    "print(f'Test PCC: {pcc_test:.3f} Val PCC: {pcc_val:.3f}')\n",
    "print(f'Test RMSE: {rmse_test:.3f} Val RMSE: {rmse_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB7CxX-Jiwm_"
   },
   "source": [
    "#### 4-2 Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6StFk7xd-vF0"
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "\n",
    "sequential_model = create_sequential_model((60, 100, 1))\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=40, monitor='val_mse', restore_best_weights=True)\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "sequential_model.compile(optimizer=adam, loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 496539,
     "status": "ok",
     "timestamp": 1599635817611,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -270
    },
    "id": "bq2mSXRHjUSi",
    "outputId": "c39e196d-6361-4345-99be-2d8ee20f6a72"
   },
   "outputs": [],
   "source": [
    "# Training Sequential model\n",
    "\n",
    "sequential_history = sequential_model.fit(strat_train_set_x, strat_train_set_y, batch_size=128, epochs=500,\n",
    "                                          validation_data=(strat_val_set_x, strat_val_set_y), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAc-MEs2jc6J"
   },
   "outputs": [],
   "source": [
    "sequential_model.save('sequential_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_TDG-Pilhzd"
   },
   "outputs": [],
   "source": [
    "y_pred_test = sequential_model.predict(test_set_x)\n",
    "y_pred_val = sequential_model.predict(strat_val_set_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "executionInfo": {
     "elapsed": 1138,
     "status": "ok",
     "timestamp": 1599644070447,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -270
    },
    "id": "hO2QuFxmlqz1",
    "outputId": "5cc2bd81-c928-4ec6-8e34-3c7135dfd416"
   },
   "outputs": [],
   "source": [
    "# Calculating metrics for Sequential model.\n",
    "\n",
    "loss_test = sequential_model.evaluate(test_set_x, test_set_y, verbose=0)\n",
    "loss_val = sequential_model.evaluate(\n",
    "    strat_val_set_x, strat_val_set_y, verbose=0)\n",
    "\n",
    "pcc_test = pearsonr(test_set_y, y_pred_test.ravel())[0]\n",
    "rmse_test = rmse(test_set_y, y_pred_test.ravel())\n",
    "\n",
    "pcc_val = pearsonr(strat_val_set_y, y_pred_val.ravel())[0]\n",
    "rmse_val = rmse(strat_val_set_y, y_pred_val.ravel())\n",
    "\n",
    "print('-------------------')\n",
    "print('Sequential Model')\n",
    "print(f'Test Loss: {loss_test[1]:.3f} Val Loss: {loss_val[1]:.3f}')\n",
    "print(f'Test PCC: {pcc_test:.3f} Val PCC: {pcc_val:.3f}')\n",
    "print(f'Test RMSE: {rmse_test:.3f} Val RMSE: {rmse_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nsVQ6H2dZ5q"
   },
   "source": [
    "#### 4-3 Inception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrnrgbKOdl2B"
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "\n",
    "inception_model = create_inception_model((60, 100, 1))\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=40, monitor='val_mse', restore_best_weights=True)\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "inception_model.compile(optimizer=adam, loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 714902,
     "status": "ok",
     "timestamp": 1601224409634,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -210
    },
    "id": "al1_femEdzp9",
    "outputId": "1c2affae-aba7-41c3-e34f-057bcd8bfbd5"
   },
   "outputs": [],
   "source": [
    "# Training Inception model.\n",
    "\n",
    "inception_history = inception_model.fit(strat_train_set_x, strat_train_set_y, batch_size=128, epochs=500,\n",
    "                                        validation_data=(strat_val_set_x, strat_val_set_y), callbacks=[es, history_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdEMlD4NtpA4"
   },
   "outputs": [],
   "source": [
    "inception_model.save('inception_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmlgSVJWtxzI"
   },
   "outputs": [],
   "source": [
    "y_pred_test = inception_model.predict(test_set_x)\n",
    "y_pred_val = inception_model.predict(strat_val_set_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "executionInfo": {
     "elapsed": 5764,
     "status": "ok",
     "timestamp": 1601224950668,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -210
    },
    "id": "brK2Vctmt7lM",
    "outputId": "568d751e-8109-4fca-cde4-d86f6f1c1bac"
   },
   "outputs": [],
   "source": [
    "# Calculating metrics for Inception model.\n",
    "\n",
    "loss_test = inception_model.evaluate(test_set_x, test_set_y, verbose=0)\n",
    "loss_val = inception_model.evaluate(\n",
    "    strat_val_set_x, strat_val_set_y, verbose=0)\n",
    "\n",
    "pcc_test = pearsonr(test_set_y, y_pred_test.ravel())[0]\n",
    "rmse_test = rmse(test_set_y, y_pred_test.ravel())\n",
    "\n",
    "pcc_val = pearsonr(strat_val_set_y, y_pred_val.ravel())[0]\n",
    "rmse_val = rmse(strat_val_set_y, y_pred_val.ravel())\n",
    "\n",
    "print('-------------------')\n",
    "print('Inception Model')\n",
    "print(f'Test Loss: {loss_test[1]:.3f} Val Loss: {loss_val[1]:.3f}')\n",
    "print(f'Test PCC: {pcc_test:.3f} Val PCC: {pcc_val:.3f}')\n",
    "print(f'Test RMSE: {rmse_test:.3f} Val RMSE: {rmse_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8ux-XbN13_a"
   },
   "source": [
    "### 5 - Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXPL0DZ92TZU"
   },
   "source": [
    "#### 5 - 1 History Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlqpfdVCno0T"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "executionInfo": {
     "elapsed": 2474,
     "status": "ok",
     "timestamp": 1599642065239,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -270
    },
    "id": "ITgipojTv4hS",
    "outputId": "6e88552d-cbd8-4588-a897-651d654958c8"
   },
   "outputs": [],
   "source": [
    "# History of training for each epoch for Sequential and Residual models.\n",
    "\n",
    "history_plot(sequential_history, residual_history,\n",
    "             'Sequential Model', 'Residual Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP-yH9Dl2XnH"
   },
   "source": [
    "#### 5 - 2 Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TS4SwSH9DmXh"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBPRLUEx2cDH"
   },
   "outputs": [],
   "source": [
    "sequential_model = tf.keras.models.load_model('sequential_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 2473,
     "status": "ok",
     "timestamp": 1599641913241,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -270
    },
    "id": "p-lwRLRL4PoP",
    "outputId": "e27e7797-1236-48c7-b9fa-730368e3fd7e"
   },
   "outputs": [],
   "source": [
    "# Plotting scatter and histogram plots jointly for Sequential model.\n",
    "\n",
    "correlation_plot(test_set_y, sequential_model.predict(test_set_x).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmFgMpOgMyuL"
   },
   "source": [
    "#### 5 - 3 Pearson's Correlation and RMSE Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcdQwOytThOh"
   },
   "outputs": [],
   "source": [
    "# Sperate Core set to their clusters id.\n",
    "\n",
    "target_clusters = {}\n",
    "\n",
    "for i in range(1, 58):\n",
    "    target_clusters[i] = []\n",
    "\n",
    "with open('CoreSet.dat') as file:\n",
    "\n",
    "    for item in file.readlines():\n",
    "\n",
    "        item = item.split()\n",
    "\n",
    "        if item[0] != '#':\n",
    "\n",
    "            target_clusters[int(item[-1])].append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ztrg4ypNjCr"
   },
   "outputs": [],
   "source": [
    "def pcc_rmse_core_set_cluster(model, pdbid_list):\n",
    "\n",
    "    x_cluster = np.array([refined_set_data[key]\n",
    "                         for key in pdbid_list]).reshape(5, 60, 100, 1)\n",
    "    y_cluster = core_set.set_index('pdbid').loc[pdbid_list].to_numpy()\n",
    "\n",
    "    y_cluster_pred = model.predict(x_cluster)\n",
    "\n",
    "    pcc_cluster = pearsonr(y_cluster.ravel(), y_cluster_pred.ravel())[0]\n",
    "    rmse_cluster = rmse(y_cluster.ravel(), y_cluster_pred.ravel())\n",
    "\n",
    "    return pcc_cluster, rmse_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqgtbcfSCuTv"
   },
   "outputs": [],
   "source": [
    "sequential_model = tf.keras.models.load_model('sequential_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VI6jTZ6gT5dz"
   },
   "outputs": [],
   "source": [
    "pcc_clusters = []\n",
    "rmse_clusters = []\n",
    "\n",
    "for item in range(1, 58):\n",
    "\n",
    "    pcc_cluster, rmse_cluster = pcc_rmse_core_set_cluster(\n",
    "        sequential_model, target_clusters[item])\n",
    "    pcc_clusters.append((item, pcc_cluster))\n",
    "    rmse_clusters.append((item, rmse_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-SUsQjSW7Yf"
   },
   "outputs": [],
   "source": [
    "pcc_clusters = sorted(pcc_clusters, key=lambda x: x[1], reverse=True)\n",
    "rmse_clusters = sorted(rmse_clusters, key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2868,
     "status": "ok",
     "timestamp": 1599649897469,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -270
    },
    "id": "mNtiH7gejoTt",
    "outputId": "1ddbbf28-ef35-477b-8c4e-8eee9d13f6f2"
   },
   "outputs": [],
   "source": [
    "# Plot Pearson's correlation bar chart for each Core set cluster id.\n",
    "\n",
    "bar_chart(pcc_clusters, 'summer', '$R_{P}$', 'pcc_bar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3439,
     "status": "ok",
     "timestamp": 1599650093234,
     "user": {
      "displayName": "milad rayka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh_c7j8c9LOUh9UhTGnR0GwVC1LjBQCb-Yb9nXFBw=s64",
      "userId": "07600852441484607172"
     },
     "user_tz": -270
    },
    "id": "hD2MsfEVaZkk",
    "outputId": "43160e18-7342-47c1-f57b-8bdc0eec852f"
   },
   "outputs": [],
   "source": [
    "# Plot RMSE bar chart for each Core set cluster id.\n",
    "\n",
    "bar_chart(rmse_clusters, 'winter', 'RMSE', 'rmse_bar.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOuEKvSI7uTpAWsu8nxaWtd",
   "collapsed_sections": [
    "vIZp7OIJqGN3",
    "4zZyeG6Bbyet",
    "jvqUNLX2cJRQ",
    "gK7ZwX_Nh7f8",
    "Q65IBpXoiDpl",
    "-Y7GbOWJU71H",
    "c98Xqg9CpjiM",
    "5JGQMsObipNq",
    "IB7CxX-Jiwm_",
    "6nsVQ6H2dZ5q",
    "mXPL0DZ92TZU",
    "LP-yH9Dl2XnH"
   ],
   "mount_file_id": "1I-YdaGmlLB8Yx10H6O6J-iL2WWPA2MNy",
   "name": "Train_and_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
